import argparse
import gc
import os
import random
import re
import sys
import torch

from datetime import datetime

# boilerplate generated by the comfy python extension
# recursively scan upwards for an item
def find_path(name: str, path: str = None) -> str:
    if path is None:
        path = os.getcwd()
    if name in os.listdir(path):
        path_name = os.path.join(path, name)
        return path_name
    parent_directory = os.path.dirname(path)
    if parent_directory == path:
        return None
    return find_path(name, parent_directory)

def add_extra_model_paths() -> None:
    from main import load_extra_path_config
    extra_model_paths = find_path("extra_model_paths.yaml")
    if extra_model_paths is not None:
        load_extra_path_config(extra_model_paths)

def import_custom_and_start() -> None:
    import asyncio
    import execution
    import server
    # FIXME - this was using the wrong name
    from nodes import init_custom_nodes as init_extra_nodes
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    server_instance = server.PromptServer(loop)
    execution.PromptQueue(server_instance)
    init_extra_nodes()

comfy_path = find_path('ComfyUI')
sys.path.append(comfy_path)

this_path = os.path.dirname(os.path.abspath(__file__))
sys.path.append(this_path)
import common
import checkpoints
from common import Silence

def main(checkpoint_list, input_filenames, input_prompts = [None], segs=['auto'], skip_segment=[], noise = 0.0, steps = 20, cycles = 2, denoise = 0.4, prompted_only = False, frontload_tags = ['rating_safe'], frontload_neg = [], mandatory_tags = [], seeds = [-1], diffusion_start = None, diffusion_stop = None, save_ora = False, output_folder='.', holdfile_path=None):
    with Silence():
        add_extra_model_paths()
        import_custom_and_start()
    from nodes import NODE_CLASS_MAPPINGS

    with torch.inference_mode():
        with Silence():
            clipEncoderClass = NODE_CLASS_MAPPINGS['CLIPTextEncode']()
            cplsClass = NODE_CLASS_MAPPINGS['CheckpointLoaderSimple']()
            imageSaverClass = NODE_CLASS_MAPPINGS['Image Saver']()
            loraLoaderClass = NODE_CLASS_MAPPINGS['LoraLoader']()
            segsFromMask = NODE_CLASS_MAPPINGS['MaskToSEGS']()
            segsDetector = NODE_CLASS_MAPPINGS['ImpactSimpleDetectorSEGS']()
            fdpClass = NODE_CLASS_MAPPINGS['DetailerForEachPipe']()
            ultraProviderClass = NODE_CLASS_MAPPINGS['UltralyticsDetectorProvider']()
            vaeLoaderClass = NODE_CLASS_MAPPINGS['VAELoader']()

            ultra_provider = ultraProviderClass.doit(model_name="bbox/face_yolov8m.pt")[0]

        # build the segment map
        segment_info = {}
        for if_idx, input_filename in enumerate(input_filenames):
            common.log(f'** working on image {if_idx}, {input_filename}')
            input_image, metadata = common.load_image_as_image_tensor(input_filename)
            if 'parameters' in metadata:
                meta_pieces = metadata['parameters'].split('\n')
                meta_for_file = f'Original metadata - Positive: {meta_pieces[0]}. '
                meta_for_file += ' '.join(x for x in meta_pieces if x.startswith('Negative prompt:'))
            else:
                meta_for_file = 'Original metadata missing or unrecoverable.'

            segments = [(input_image.shape[1], input_image.shape[2]), []]
            for seg_program in segs:
                if seg_program == 'auto':
                    auto_segs = segsDetector.detect(
                        bbox_detector = ultra_provider,
                        image = input_image,
                        bbox_threshold = 0.5,
                        bbox_dilation = 10,
                        crop_factor = 1.5,
                        drop_size = 10,
                        sub_threshold = 0.5,
                        sub_dilation = 0,
                        sub_bbox_expansion = 0,
                        sam_mask_hint_threshold = 0.7,
                        post_dilation = 0,
                        sam_model_opt = None,
                        segm_detector_opt = None,
                        detailer_hook = None
                    )[0]
                    segments[1].extend(auto_segs[1])
                else:
                    mask_value = 1
                    mask_tensor = torch.full((1, segments[0][0], segments[0][1]), 1 - mask_value, dtype=torch.float32)
                    for l, t, w, h in seg_program:
                        mask_tensor[0, t:t+h, l:l+w] = mask_value
                    mask_segs = segsFromMask.doit(
                        mask=mask_tensor,
                        combined=True,
                        crop_factor=3.0,
                        bbox_fill=False,
                        drop_size=1,
                        contour_fill=False
                    )[0]
                    segments[1].extend(mask_segs[1])
            
            common.log(f'** {len(segments[1])} segments detected')
            # sort segments from left to right, top to bottom
            segments[1].sort(key = lambda x: (x.bbox[0], x.bbox[1]))
            common.log('** resorting segments left to right, top to bottom.')
            if skip_segment:
                if len(segments[1]) == 1:
                    common.log('** won\'t skip as you only have one segment.')
                else:
                    for index in skip_segment:
                        if index < len(segments[1]):
                            common.log(f'** removing segment {index}')
                            segments[1][index] = None
                        else:
                            common.log(f'** tried to remove out of range segment at {index}')
                    segments[1] = [x for x in segments[1] if x]
                    common.log(f'** {len(segments[1])} segments remain')

            segment_info[input_filename] = {'segments': segments, 'meta_for_file': meta_for_file, 'input_image': input_image}

        for checkpoint_tuple in checkpoint_list:
            if not checkpoint_tuple:
                checkpoint_tuple = random.choice(list(checkpoints.everything_d.values()))
            common.log(f'** selected {checkpoint_tuple}')
            checkpoint_shortname, checkpoint, lora, positive_stem, negative_stem, vae_name = checkpoint_tuple
            for cpe in frontload_tags:
                positive_stem += f', {cpe}'
            for cpe in frontload_neg:
                negative_stem += f', {cpe}'

            base_model, clip_object, _ = cplsClass.load_checkpoint(ckpt_name=checkpoint)
            vae = vaeLoaderClass.load_vae(vae_name=vae_name)[0]

            # lora manglement - we'll need to revisit the issue of prompt embedded lora
            lora_list = ([(lora, 0.7, 0.7)] if lora else [])
            for lora, ms, cs in lora_list:
                common.log(f'** patching model with lora:{lora}:{ms}:{cs}')
                lora_result = loraLoaderClass.load_lora(lora_name = lora, strength_model = ms, strength_clip = cs, model = base_model, clip = clip_object)
                base_model = lora_result[0]
                clip_object = lora_result[1]

            # set clip skip
            clip_object.clip_layer(-2)

            # create "empty" conditionings for face detailing - 
            # the pos here will also be our default if we run out of special purpose wildcards
            positive_d_cond = common.scramble_embedding(clipEncoderClass.encode(text = positive_stem, clip=clip_object)[0], noise)
            negative_d_cond = common.scramble_embedding(clipEncoderClass.encode(text = negative_stem, clip=clip_object)[0], noise)

            for prompt_idx, input_prompt in enumerate(input_prompts):
                if input_prompt == 'auto':
                    wildcard_body = ''
                elif input_prompt:
                    ip_chunks = input_prompt.split('|')
                    wildcard_body = '[ASC]'
                    for ip in ip_chunks:
                        stripped_prompt, _ = common.extract_lora_keywords(ip)
                        stripped_prompt = f'{positive_stem}, {stripped_prompt}'
                        for q in mandatory_tags:
                            if q not in stripped_prompt:
                                stripped_prompt = f'{stripped_prompt}, {q}'
                        wildcard_body += f'\n{stripped_prompt} [SEP]'
                    common.log(f'** wildcard is: {wildcard_body}')
                else:
                    wildcard_body = ''

            # if wildcard_body is blank, this is effectively an unprompted run
            basic_pipes = [((base_model, clip_object, vae, positive_d_cond, negative_d_cond), wildcard_body)]            
            # if we do have a wildcard and we're happy to have an unprompted run...
            if wildcard_body and not prompted_only:
                basic_pipes.append(((base_model, clip_object, vae, positive_d_cond, negative_d_cond), ''))

            input_keys = segment_info.keys()

            for input_idx, input_fn in enumerate(input_keys):
                common.log(f'** starting repair of file {input_idx+1} of {len(input_keys)}, {input_fn}')
                segments = segment_info[input_fn]['segments']
                meta_for_file = segment_info[input_fn]['meta_for_file']
                input_image = segment_info[input_fn]['input_image']

                detailer_images = []
                for pipe_idx, basic_pipe_t in enumerate(basic_pipes):
                    basic_pipe, wildcard = basic_pipe_t
                    for detailer_seed in seeds:
                        detailer_seed = common.rseed(detailer_seed)
                        if(diffusion_start and diffusion_stop): common.sleep_while_outside(diffusion_start, diffusion_stop)
                        common.sleep_while_holdfile(holdfile_path)
                        common.log(f'** running detailer pipe {pipe_idx+1} of {len(basic_pipes)} with seed {detailer_seed}')
                        face_detailer = fdpClass.doit(
                            image = input_image,
                            segs = segments,
                            guide_size = 1024,
                            guide_size_for='bbox',
                            max_size=1024,
                            seed=detailer_seed,
                            steps=steps,
                            cfg=7.5,
                            sampler_name='euler_ancestral',
                            scheduler='normal',
                            denoise=denoise,
                            feather=5,
                            noise_mask=True,
                            force_inpaint=True,
                            basic_pipe=basic_pipe,
                            wildcard=wildcard,
                            refiner_ratio=None,
                            detailer_hook=None,
                            refiner_basic_pipe_opt=None,
                            cycle=cycles,
                            inpaint_model=False,
                            noise_mask_feather=20,
                            scheduler_func_opt=None
                        )
                        detailer_images.append((detailer_seed, face_detailer[0]))

                common.log(f'** writing {len(detailer_images)} images')
                for (out_idx, out_img_t) in enumerate(detailer_images):
                    detailer_seed, out_img = out_img_t
                    # half of this metadata is wrong but a1111 doesn't really understand multistage generation
                    out_height = out_img.shape[1]
                    out_width = out_img.shape[2]
                    saver = imageSaverClass.save_files(
                        filename=f'fr_{checkpoint_shortname}_{if_idx}_%time_%seed_{prompt_idx}_{out_idx}',
                        path=output_folder,
                        extension="png",
                        steps=25,
                        cfg=7.5,
                        modelname=checkpoint,
                        sampler_name="euler_ancestral",
                        scheduler="normal",
                        positive=wildcard_body + ' === ' + meta_for_file,
                        negative=negative_stem,
                        seed_value=detailer_seed,
                        width=out_width,
                        height=out_height,
                        lossless_webp=True,
                        quality_jpeg_or_webp=100,
                        optimize_png=False,
                        counter=0,
                        denoise=1,
                        time_format="%Y-%m-%d-%H%M%S",
                        save_workflow_as_json=False,
                        embed_workflow_in_png=False,
                        strip_a1111_params="nothing",
                        images=out_img,
                    )

                if save_ora:
                    common.save_images_to_ora(input_image, detailer_images, f'{output_folder}/ora_t2i_{checkpoint_shortname}_{if_idx}_{datetime.now().strftime("%Y-%m-%d-%H%M%S")}.ora')
                                
            del base_model, clip_object
            gc.collect()
            torch.cuda.empty_cache()

def parse_args():
    acceptable_checkpoints = list(checkpoints.everything_d.keys()) + ['*']

    parser = argparse.ArgumentParser()
    parser.add_argument('--checkpoints', nargs='+', choices=acceptable_checkpoints, default=['*'], help="List of checkpoints. Default is ['*'].")
    parser.add_argument('--input_filenames', type=common.args_valid_file_path, nargs='+', help="List of images to process.")

    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument('--prompts', nargs='+', help="List of prompts")
    group.add_argument('--prompt_file', type=common.args_read_prompts_from_file, help="File with prompts (one per line)")

    parser.add_argument('--prompted_only', action='store_true', default=False, help="Only facefix with prompts. Default is False.")
    parser.add_argument('--segs', nargs='+', type=common.args_parse_bounding_box, default=['auto'], help='List of segments l:t+w+h or \'auto\' (the default).')

    parser.add_argument('--skip_segment', type=int, nargs='+', default=[], help='Segment indexes to skip.')

    parser.add_argument('--save_ora', action='store_true', default=False, help="Save ORA file after detailing. Default is False.")

    parser.add_argument('--steps', type=int, default=20, help="Number of steps to take (default 20).")
    parser.add_argument('--denoise', type=float, default=0.4, help="Detailer denoise strength (default 0.4).")
    parser.add_argument('--cycles', type=int, default=4, help="Detailing cycles (default 4).")

    parser.add_argument('--noise', type=float, default=0, help="Noise strength, applied to all embeddings. Default 0.0.")

    parser.add_argument('--frontload_tags', nargs='+', default=['rating_safe'], help="Frontload tags. Default is ['rating_safe'].")
    parser.add_argument('--frontload_neg', nargs='+', default=[], help="Frontload negative tags. Default is [].")
    parser.add_argument('--mandatory_tags', nargs='+', default=[], help="Mandatory tags. Default is [].")

    parser.add_argument('--seeds', nargs='+', type=int, default=[-1], help="List of seeds. Default is [-1]. -1 is reevaluated each time, use -2 for a 'fixed random' seed.")

    parser.add_argument('--diff_start', type=common.args_validate_time, default=None, help="Diffusion start time in 'HH:MM' format.")
    parser.add_argument('--diff_stop', type=common.args_validate_time, default=None, help="Diffusion end time in 'HH:MM' format.")

    parser.add_argument('--output_folder', type=str, default='.', help="Output folder path. Default is '.', or the comfy output folder.")
    parser.add_argument('--hold_file', type=str, default='hold.txt', help="Holdfile path. Default is 'hold.txt' in the CWD.")

    return parser.parse_args()

if __name__ == '__main__':
    args = parse_args()
    common.log(args)

    checkpoint_list = [checkpoints.everything_d[x] if x != '*' else None for x in args.checkpoints ]
    
    if args.prompts:
        input_prompts = args.prompts
    else:
        input_prompts = args.prompt_file
    if input_prompts == ['auto']:
        input_prompts = [None]
    

    # -2 is a "fixed random seed" which is generated once and then stays the same
    # -1 is the classic random seed which regenerates every time it is called on
    seeds = [common.rseed(-1) if x == -2 else x for x in args.seeds]

    # prevent comfy from complaining about my args
    sys.argv = [sys.argv[0]]

    main(
        checkpoint_list,
        input_filenames=args.input_filenames,
        input_prompts=input_prompts, 
        noise=args.noise,
        steps=args.steps,
        cycles=args.cycles,
        denoise=args.denoise,
        prompted_only=args.prompted_only,
        segs=args.segs,
        skip_segment=args.skip_segment,
        frontload_tags = args.frontload_tags,
        frontload_neg = args.frontload_neg,
        mandatory_tags = args.mandatory_tags,
        seeds=seeds,
        diffusion_start = args.diff_start,
        diffusion_stop = args.diff_stop,
        save_ora = args.save_ora,
        holdfile_path = args.hold_file,
        output_folder = args.output_folder
    )
